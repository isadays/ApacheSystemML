{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install Java\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Download and install Spark\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.1/spark-3.0.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.0.1-bin-hadoop2.7.tgz\n",
        "\n",
        "# Install findspark, a Python library that makes it easier to find Spark\n",
        "!pip install findspark\n",
        "\n",
        "# Install SystemML\n",
        "!pip install systemml\n",
        "\n",
        "# Downgrade pandas to a compatible version\n",
        "!pip install pandas==1.3.3\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "baY7ApqozTdV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff7f9655-1337-4c1e-a88c-998afcc5dd53"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n",
            "Collecting systemml\n",
            "  Downloading systemml-1.2.0.tar.gz (9.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.10/dist-packages (from systemml) (1.25.2)\n",
            "Requirement already satisfied: scipy>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from systemml) (1.11.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from systemml) (2.0.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from systemml) (1.2.2)\n",
            "Requirement already satisfied: Pillow>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from systemml) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->systemml) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->systemml) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->systemml) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->systemml) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->systemml) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->systemml) (1.16.0)\n",
            "Building wheels for collected packages: systemml\n",
            "  Building wheel for systemml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for systemml: filename=systemml-1.2.0-py3-none-any.whl size=9724751 sha256=dbdf6b9a68d1224f936976eb7447a1af986e8d8404588b26069c45c69854c46f\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/07/c6/424fdc481cf79ca7506a4933ee73f814e3d26900b028c029d0\n",
            "Successfully built systemml\n",
            "Installing collected packages: systemml\n",
            "Successfully installed systemml-1.2.0\n",
            "Collecting pandas==1.3.3\n",
            "  Downloading pandas-1.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from pandas==1.3.3) (1.25.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from pandas==1.3.3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.10/dist-packages (from pandas==1.3.3) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7.3->pandas==1.3.3) (1.16.0)\n",
            "Installing collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.0.3\n",
            "    Uninstalling pandas-2.0.3:\n",
            "      Successfully uninstalled pandas-2.0.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 1.6.0 requires pandas>=1.5.0, but you have pandas 1.3.3 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.3.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 1.3.3 which is incompatible.\n",
            "mizani 0.9.3 requires pandas>=1.3.5, but you have pandas 1.3.3 which is incompatible.\n",
            "plotnine 0.12.4 requires pandas>=1.5.0, but you have pandas 1.3.3 which is incompatible.\n",
            "statsmodels 0.14.2 requires pandas!=2.1.0,>=1.4, but you have pandas 1.3.3 which is incompatible.\n",
            "xarray 2023.7.0 requires pandas>=1.4, but you have pandas 1.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-1.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop2.7\"\n",
        "os.environ[\"PATH\"] += f\":{os.environ['SPARK_HOME']}/bin\"\n",
        "\n"
      ],
      "metadata": {
        "id": "bkuJLTgd368h"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .appName(\"DML Script Example\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "from systemml import MLContext, dml\n",
        "\n",
        "# Create an MLContext\n",
        "ml = MLContext(spark)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I489G0FR2PNB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the DML script\n",
        "dml_script = \"\"\"\n",
        "gen_wave = function(double freq, double amp, integer T, integer Hz, double pi_value) return (matrix[double] x) {\n",
        "    time = seq(0, T-T/Hz, T/Hz)\n",
        "    x = amp * sin(2 * pi_value * freq * time)\n",
        "}\n",
        "\n",
        "PI = 3.141592654\n",
        "x = gen_wave(2, 1, 1, 50, PI)\n",
        "N = nrow(x)\n",
        "print(toString(x, sep=\"\\\\t\\\\t\", decimal=1))\n",
        "print(N)\n",
        "\"\"\"\n",
        "\n",
        "# Execute the DML script\n",
        "ml.execute(dml(dml_script))\n",
        "\n"
      ],
      "metadata": {
        "id": "q56XMj-x2btX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c278678f-f6a8-4f1e-f723-24bba5ca93ca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANTLR Tool version 4.5.3 used for code generation does not match the current runtime version 4.7.1ANTLR Runtime version 4.5.3 used for parser compilation does not match the current runtime version 4.7.1ANTLR Tool version 4.5.3 used for code generation does not match the current runtime version 4.7.1ANTLR Runtime version 4.5.3 used for parser compilation does not match the current runtime version 4.7.1\n",
            "0.0\n",
            "0.249\n",
            "0.482\n",
            "0.685\n",
            "0.844\n",
            "0.951\n",
            "0.998\n",
            "0.982\n",
            "0.905\n",
            "0.771\n",
            "0.588\n",
            "0.368\n",
            "0.125\n",
            "-0.125\n",
            "-0.368\n",
            "-0.588\n",
            "-0.771\n",
            "-0.905\n",
            "-0.982\n",
            "-0.998\n",
            "-0.951\n",
            "-0.844\n",
            "-0.685\n",
            "-0.482\n",
            "-0.249\n",
            "0.0\n",
            "0.249\n",
            "0.482\n",
            "0.685\n",
            "0.844\n",
            "0.951\n",
            "0.998\n",
            "0.982\n",
            "0.905\n",
            "0.771\n",
            "0.588\n",
            "0.368\n",
            "0.125\n",
            "-0.125\n",
            "-0.368\n",
            "-0.588\n",
            "-0.771\n",
            "-0.905\n",
            "-0.982\n",
            "-0.998\n",
            "-0.951\n",
            "-0.844\n",
            "-0.685\n",
            "-0.482\n",
            "-0.249\n",
            "\n",
            "50\n",
            "SystemML Statistics:\n",
            "Total execution time:\t\t0.040 sec.\n",
            "Number of executed Spark inst:\t0.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLResults"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}