{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install Java\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Download and install Spark\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.1/spark-3.0.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.0.1-bin-hadoop2.7.tgz\n",
        "\n",
        "# Install findspark, a Python library that makes it easier to find Spark\n",
        "!pip install findspark\n",
        "\n",
        "# Install SystemML\n",
        "!pip install systemml\n",
        "\n",
        "# Downgrade pandas to a compatible version\n",
        "!pip install pandas==1.3.3\n"
      ],
      "metadata": {
        "id": "baY7ApqozTdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop2.7\"\n",
        "os.environ[\"PATH\"] += f\":{os.environ['SPARK_HOME']}/bin\"\n",
        "\n"
      ],
      "metadata": {
        "id": "bkuJLTgd368h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .appName(\"DML Script Example\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "from systemml import MLContext, dml\n",
        "\n",
        "# Create an MLContext\n",
        "ml = MLContext(spark)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I489G0FR2PNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the DML script\n",
        "dml_script = \"\"\"\n",
        "gen_wave = function(double freq, double amp, integer T, integer Hz, double pi_value) return (matrix[double] x) {\n",
        "    time = seq(0, T-T/Hz, T/Hz)\n",
        "    x = amp * sin(2 * pi_value * freq * time)\n",
        "}\n",
        "\n",
        "PI = 3.141592654\n",
        "x = gen_wave(2, 1, 1, 50, PI)\n",
        "N = nrow(x)\n",
        "print(toString(x, sep=\"\\\\t\\\\t\", decimal=1))\n",
        "print(N)\n",
        "\"\"\"\n",
        "\n",
        "# Execute the DML script\n",
        "ml.execute(dml(dml_script))\n",
        "\n"
      ],
      "metadata": {
        "id": "q56XMj-x2btX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}