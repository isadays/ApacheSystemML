{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!pip install pyspark\n",
        "!pip install findspark\n"
      ],
      "metadata": {
        "id": "baY7ApqozTdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"HMP Dataset Example\") \\\n",
        "    .getOrCreate()\n",
        "\n"
      ],
      "metadata": {
        "id": "UjzJcMTOzbMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nX3p1hCdq_Fe"
      },
      "outputs": [],
      "source": [
        "!rm -Rf HMP_Dataset\n",
        "!git clone https://github.com/wchill/HMP_Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, IntegerType\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"x\", IntegerType(), True),\n",
        "    StructField(\"y\", IntegerType(), True),\n",
        "    StructField(\"z\", IntegerType(), True)])"
      ],
      "metadata": {
        "id": "L0WyhvBIrO-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import fnmatch\n",
        "\n",
        "d = 'HMP_Dataset/'\n",
        "\n",
        "# filter list for all folders containing data (folders that don't start with .)\n",
        "file_list_filtered = [s for s in os.listdir(d) if os.path.isdir(os.path.join(d,s)) & ~fnmatch.fnmatch(s, '.*')]\n",
        "\n",
        "from pyspark.sql.functions import lit\n",
        "\n",
        "#create pandas data frame for all the data\n",
        "\n",
        "df = None\n",
        "\n",
        "for category in file_list_filtered:\n",
        "    data_files = os.listdir('HMP_Dataset/'+category)\n",
        "\n",
        "    #create a temporary pandas data frame for each data file\n",
        "    for data_file in data_files:\n",
        "        print(data_file)\n",
        "        temp_df = spark.read.option(\"header\", \"true\").option(\"header\", \"false\").option(\"delimiter\", \" \").csv('HMP_Dataset/'+category+'/'+data_file,schema=schema)\n",
        "\n",
        "        #create a column called \"source\" storing the current CSV file\n",
        "        temp_df = temp_df.withColumn(\"source\", lit(data_file))\n",
        "\n",
        "        #create a column called \"class\" storing the current data folder\n",
        "        temp_df = temp_df.withColumn(\"class\", lit(category))\n",
        "\n",
        "        #append to existing data frame list\n",
        "        #data_frames = data_frames + [temp_df]\n",
        "\n",
        "        if df is None:\n",
        "            df = temp_df\n",
        "        else:\n",
        "            df = df.union(temp_df)"
      ],
      "metadata": {
        "id": "SepNj2bq3_Iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splits = df.randomSplit([0.8, 0.2])\n",
        "df_train = splits[0]\n",
        "df_test = splits[1]"
      ],
      "metadata": {
        "id": "LPIe98Dj4aw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.feature import OneHotEncoder\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.feature import Normalizer\n",
        "\n",
        "indexer = StringIndexer(inputCol=\"class\", outputCol=\"label\")\n",
        "encoder = OneHotEncoder(inputCol=\"label\", outputCol=\"labelVec\")\n",
        "vectorAssembler = VectorAssembler(inputCols=[\"x\",\"y\",\"z\"],outputCol=\"features\")\n",
        "normalizer = Normalizer(inputCol=\"features\", outputCol=\"features_norm\", p=1.0)"
      ],
      "metadata": {
        "id": "HZxpRNq84kTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import GBTClassifier\n",
        "\n",
        "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features_norm\", maxIter=10)"
      ],
      "metadata": {
        "id": "B2jSXxLn4oMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "\n",
        "pipeline = Pipeline(stages=[indexer, encoder, vectorAssembler, normalizer, gbt])"
      ],
      "metadata": {
        "id": "H14_BzV_LafC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = pipeline.fit(df_train)"
      ],
      "metadata": {
        "id": "v2l7TzJkLkSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.transform(df_train)"
      ],
      "metadata": {
        "id": "RaAAKkIZLmgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = pipeline.fit(df_test)"
      ],
      "metadata": {
        "id": "W3X_gVcbLt6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.transform(df_test)"
      ],
      "metadata": {
        "id": "I75OZP05Lt6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "binEval = MulticlassClassificationEvaluator().setMetricName(\"accuracy\") .setPredictionCol(\"prediction\").setLabelCol(\"label\")"
      ],
      "metadata": {
        "id": "dWWEFnyWMVRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BinEval.evaluate(prediction)"
      ],
      "metadata": {
        "id": "cC-waLlHMD8s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}